{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the hands, rocks and papers images, in total 2749."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch.utils.data as Data\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "#data loader, load all the png images in the path loader and save them in a list and return the list as a numpy\n",
    "def data_loader(path,label):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    #search the path and load all the png images\n",
    "    for file in os.listdir(path):\n",
    "        if file.endswith(\".png\"):\n",
    "            img = Image.open(path + \"/\"+ file)\n",
    "            #resize the image to 32*32\n",
    "            img = img.resize((128,128))\n",
    "            img = np.array(img)\n",
    "            data_list.append(img.reshape(128,128,3))\n",
    "            label_list.append(label)\n",
    "    #transform the list into a numpy array\n",
    "    data_list = np.array(data_list)\n",
    "    label_list = np.array(label_list)\n",
    "    \n",
    "    #reshape the numpy array into 2 dimensions\n",
    "    # data_list = data_list.reshape(data_list.shape[0],1,data_list.shape[1],data_list.shape[2]) \n",
    "    return data_list,label_list\n",
    "data_paper,paper_label=data_loader('../../db/paper',0)\n",
    "data_rock,rock_label = data_loader('../../db/rock',1)\n",
    "data_scissor,scissor_label = data_loader('../../db/scissors',2)\n",
    "data_list = np.concatenate((data_paper,data_rock,data_scissor))\n",
    "label_list = np.concatenate((paper_label,rock_label,scissor_label))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2749, 128, 128, 3)\n",
      "(2199, 128, 128, 3) (2199, 3) (550, 128, 128, 3) (550, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import tensorflow.keras.utils\n",
    "print(data_list.shape)\n",
    "#standardize the data\n",
    "data = data_list\n",
    "label=label_list\n",
    "#split the data into train and test\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(data,label,test_size=0.2,random_state=42)\n",
    "# change to one hot encoding\n",
    "Y_train = tensorflow.keras.utils.to_categorical(Y_train, 3)\n",
    "Y_test = tensorflow.keras.utils.to_categorical(Y_test, 3)\n",
    "print(X_train.shape,Y_train.shape,X_test.shape,Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define 3 layers shallow convolution networks, use ImageDataGenerator to do the data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#imagedatagenetator\n",
    "\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=True,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=True,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=60,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same', input_shape=(128,128,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))   # \n",
    "model.add(Dropout(0.2))                     # \n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "#print the model using plot_model\n",
    "import pydot\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "plot_model(model, to_file='model.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = \"cnn.h5\"\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "# checkpoint\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model.fit(datagen.flow(X_train,Y_train),\n",
    "          validation_data=(X_test,Y_test),\n",
    "          epochs=100,\n",
    "          callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 190ms/step - loss: 22.8302 - accuracy: 0.9455\n",
      "[22.830196380615234, 0.9454545378684998]\n"
     ]
    }
   ],
   "source": [
    "#load the model by using tensorflow\n",
    "from keras.models import load_model\n",
    "test_model = load_model('../saved_models/cnn.h5')\n",
    "print(test_model.evaluate(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "[[0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#paper 0 ,rock 1, scissor 2\n",
    "import matplotlib.pyplot as plt\n",
    "img = Image.open(\"/Users/xiewenxuan/Downloads/rock-paper-scissors copy/db/test.png\")\n",
    "#resize the image to 32*32\n",
    "img = img.resize((32,32))\n",
    "img = np.array(img)\n",
    "img = img.reshape(1,32,32,3)\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "print(test_model.predict(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "95e37875f513ea70d5edee3c7b85515c85d771255e1398505331c1bde3bc5b47"
  },
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
